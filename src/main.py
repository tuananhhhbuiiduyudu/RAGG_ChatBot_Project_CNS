"""
File chÃ­nh Ä‘á»ƒ cháº¡y á»©ng dá»¥ng Chatbot AI
Chá»©c nÄƒng: 
- Táº¡o giao diá»‡n web vá»›i Streamlit
- Xá»­ lÃ½ tÆ°Æ¡ng tÃ¡c chat vá»›i ngÆ°á»i dÃ¹ng
- Káº¿t ná»‘i vá»›i AI model Ä‘á»ƒ tráº£ lá»i
"""
# === IMPORT CÃC THÆ¯ VIá»†N Cáº¦N THIáº¾T ===
import streamlit as st  # ThÆ° viá»‡n táº¡o giao diá»‡n web
from dotenv import load_dotenv  # Äá»c file .env chá»©a API key
from seed_data import seed_milvus, seed_milvus_live  # HÃ m xá»­ lÃ½ dá»¯ liá»‡u
from agent import get_retriever as get_openai_retriever, get_llm_and_agent as get_openai_agent
from local_ollama import get_retriever as get_ollama_retriever, get_llm_and_agent as get_ollama_agent
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

# === THIáº¾T Láº¬P GIAO DIá»†N TRANG WEB ===
def setup_page():
    """
    Cáº¥u hÃ¬nh trang web cÆ¡ báº£n
    """
    st.set_page_config(
        page_title="AI Assistant",  # TiÃªu Ä‘á» tab trÃ¬nh duyá»‡t
        page_icon="ğŸ’¬",  # Icon tab
        layout="wide"  # Giao diá»‡n rá»™ng
    )

# === KHá»I Táº O á»¨NG Dá»¤NG ===
def initialize_app():
    """
    Khá»Ÿi táº¡o cÃ¡c cÃ i Ä‘áº·t cáº§n thiáº¿t:
    - Äá»c file .env chá»©a API key
    - Cáº¥u hÃ¬nh trang web
    """
    load_dotenv()  # Äá»c API key tá»« file .env
    setup_page()  # Thiáº¿t láº­p giao diá»‡n

# === THANH CÃ”NG Cá»¤ BÃŠN TRÃI ===
def setup_sidebar():
    """
    Táº¡o thanh cÃ´ng cá»¥ bÃªn trÃ¡i vá»›i cÃ¡c tÃ¹y chá»n
    """
    with st.sidebar:
        st.title("âš™ï¸ Cáº¥u hÃ¬nh")
        
        # Pháº§n 1: Chá»n Embeddings Model
        st.header("ğŸ”¤ Embeddings Model")
        embeddings_choice = st.radio(
            "Chá»n Embeddings Model:",
            ["OpenAI", "Ollama"]
        )
        use_ollama_embeddings = (embeddings_choice == "Ollama")
        
        # Pháº§n 2: Cáº¥u hÃ¬nh Data
        st.header("ğŸ“š Nguá»“n dá»¯ liá»‡u")
        data_source = st.radio(
            "Chá»n nguá»“n dá»¯ liá»‡u:",
            ["File Local", "URL trá»±c tiáº¿p"]
        )
        
        # Xá»­ lÃ½ nguá»“n dá»¯ liá»‡u dá»±a trÃªn embeddings Ä‘Ã£ chá»n
        if data_source == "File Local":
            handle_local_file(use_ollama_embeddings)
        else:
            handle_url_input(use_ollama_embeddings)
            
        # ThÃªm pháº§n chá»n collection Ä‘á»ƒ query
        st.header("ğŸ” Collection Ä‘á»ƒ truy váº¥n")
        collection_to_query = st.text_input(
            "Nháº­p tÃªn collection cáº§n truy váº¥n:",
            "data_test",
            help="Nháº­p tÃªn collection báº¡n muá»‘n sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin"
        )
        
        # Pháº§n 3: Chá»n Model Ä‘á»ƒ tráº£ lá»i
        st.header("ğŸ¤– Model AI")
        model_choice = st.radio(
            "Chá»n AI Model Ä‘á»ƒ tráº£ lá»i:",
            ["OpenAI GPT-4", "OpenAI Grok", "Ollama (Local)"]
        )
        
        return model_choice, collection_to_query